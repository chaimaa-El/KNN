{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9fc715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn predefinie-classification: [1]\n",
      "knn predefinie-regression: [6.46333333]\n"
     ]
    }
   ],
   "source": [
    "X=[[0],[1],[2],[3]]\n",
    "y1=[0,0,1,1]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh=KNeighborsClassifier(n_neighbors=3,metric=\"euclidean\")\n",
    "neigh.fit(X,y1)\n",
    "print('Knn predefinie-classification:',neigh.predict([[2.1]]))\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_regression=KNeighborsRegressor(3)\n",
    "y2=[15.3,8.6,6.5,4.29]\n",
    "knn_regression.fit(X,y2)\n",
    "print('knn predefinie-regression:',knn_regression.predict([[2.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ad009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from numpy import *\n",
    "import math\n",
    "def mean(labels):\n",
    "    \"\"\"calcul de la moyenne des k étiquettes\"\"\"\n",
    "    return sum(labels)/len(labels)\n",
    "def mode(labels):\n",
    "    \"\"\"calcul du mode des k étiquettes\"\"\"\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "def euclidean_distance(point1,point2):\n",
    "    \"\"\"calcul de la distance euclidienne\"\"\"\n",
    "    sum_squared_distance=0\n",
    "    for i in range(len(point1)):\n",
    "        sum_squared_distance+=math.pow(point1[i]-point2[i],2)\n",
    "    return math.sqrt(sum_squared_distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ad7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92093e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from numpy import *\n",
    "import math\n",
    "def mean(labels):\n",
    "    \"\"\"calcul de la moyenne des k étiquettes\"\"\"\n",
    "    return sum(labels)/len(labels)\n",
    "def mode(labels):\n",
    "    \"\"\"calcul du mode des k étiquettes\"\"\"\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "def euclidean_distance(point1,point2):\n",
    "    \"\"\"calcul de la distance euclidienne\"\"\"\n",
    "    sum_squared_distance=0\n",
    "    for i in range(len(point1)):\n",
    "        sum_squared_distance+=math.pow(point1[i]-point2[i],2)\n",
    "    return math.sqrt(sum_squared_distance)\n",
    "\n",
    "def knn(data,query,k,distance_utilisee,choix_knn_regress_ou_classif):\n",
    "    \"\"\"Algorithme des k plus proches voisins KNN\"\"\"\n",
    "    distances_et_positions=[]\n",
    "    for index,example in enumerate(data):\n",
    "        distance=distance_utilisee(example[:-1],query)\n",
    "        distances_et_positions.append((distance,index))\n",
    "    sorted_distances_et_positions=sorted(distances_et_positions)\n",
    "    k_proches_distances_and_indices=sorted_distances_et_positions[:k]\n",
    "    k_prohes_classes=[]\n",
    "    for dist_indice in k_proches_distances_and_indices:\n",
    "        num=dist_indice[1];k_prohes_classes+=[data[num][1]]\n",
    "    return k_proches_distances_and_indices\n",
    "\n",
    "        \n",
    "a=array([[1,2,1],[1,0,1],[2,0,1],[1,1,1],[0,1,0],[2,6,5]])\n",
    "b=knn(a,[1,1,1],3,euclidean_distance,mean)\n",
    "print(b)\n",
    "for i in range(len(b)):\n",
    "    print(a[b[i][1]])     \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12ddd34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 3), (1.0, 0), (1.0, 1)]\n",
      "[1 1 1]\n",
      "[1 2 1]\n",
      "[1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import math\n",
    "a=array([[1,2,1],[1,0,1],[2,0,1],[1,1,1],[0,1,0],[2,6,5]])\n",
    "b=knn(a,[1,1,1],3,euclidean_distance,mean)\n",
    "print(b)\n",
    "for i in range(len(b)):\n",
    "    print(a[b[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afed172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA as pca_dec\n",
    "\n",
    "from plot_utils import pca_scree_plot\n",
    "import pickle as pk\n",
    "\n",
    "from data import Data\n",
    "\n",
    "\n",
    "class Pca:\n",
    "    def init(self, data: Data, load=True, pkl_pca_path=\"pca_None.pkl\", var_exp=None, k=60):\n",
    "        self.data = data\n",
    "        if load:  # load pca model\n",
    "            self.pca = pk.load(open(pkl_pca_path, 'rb'))\n",
    "        else:\n",
    "            # Apply PCA to extract eigenvectors\n",
    "            self.pca = pca_dec(var_exp).fit(self.data.flat_scans)\n",
    "            # save PCA model\n",
    "            pk.dump(self.pca, open(pkl_pca_path, \"wb\"))\n",
    "        # Getting the cumulative variance\n",
    "        self.var_cumu = np.cumsum(self.pca.explained_variance_ratio_) * 100\n",
    "\n",
    "        # define number of components\n",
    "        if not var_exp:\n",
    "            self.k = k\n",
    "        else:\n",
    "            self.k = pca.cumulative_Explained_Variance(var_exp)\n",
    "\n",
    "        # Take the first K principal components as eigenvectors\n",
    "        self.eigenmesh = self.k_principal_components(self.k)\n",
    "\n",
    "        # Generate weights as a KxN matrix where K is the number of eigenvectors and N the number of samples\n",
    "        self.weights = self.eigenmesh @ (self.data.flat_scans - self.pca.mean_).T  # new data\n",
    "        # mean and standard deviation\n",
    "        self.mu = self.weights.mean()\n",
    "        self.sigma = self.weights.std()\n",
    "\n",
    "        # print(\"Weights shape: \",self.weights.shape)\n",
    "        print(\"PCA Model loaded/cretedt successfully!\")\n",
    "\n",
    "    def cumulative_Explained_Variance(self, threshold=95, show_fig=False):\n",
    "# -- creating scree plot --\n",
    "        # How many PCs explain 95% of the variance?\n",
    "        k = np.argmax(self.var_cumu > threshold) + 1\n",
    "        print(f\"Number of components explaining {threshold}% variance: \" + str(k))\n",
    "        # print(\"\\n\")\n",
    "        pca_scree_plot(self.var_cumu, k, threshold, show_fig)\n",
    "        return k\n",
    "\n",
    "    def k_principal_components(self, k):\n",
    "        # get related eigen data to k components\n",
    "        eigenmesh = self.pca.components_[:k]\n",
    "        # print(f'Shape of eigenmesh : {eigenmesh.shape}')\n",
    "        return eigenmesh\n",
    "\n",
    "    def random_weights(self, mu, sigma, k):\n",
    "        # generate random weights with a normal distribution\n",
    "        return random.normal(mu, sigma, k)\n",
    "\n",
    "    def create_random(self, k, mu=None, sigma=None, eigenmesh=None, data_mean=None):\n",
    "        # create random 3d mesh\n",
    "        # weights = self.random_weights(mu, sigma, k)\n",
    "        weights = np.zeros(k)\n",
    "        newscan = weights @ eigenmesh + data_mean\n",
    "        newscan = newscan.reshape(self.data.scan_shape)\n",
    "        return newscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d78bf071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score sur test-set par k=5 -->85.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "data=pandas.read_csv(\"images_chiffres_codees_niveau_de_gris.csv\")\n",
    "data=np.array(data);x=data[0:1000,1:];y=data[0:1000,0];\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "model=KNeighborsClassifier(n_neighbors=5,metric='manhattan')\n",
    "model.fit(x_train,y_train);score=model.score(x_test,y_test)\n",
    "print(\"score sur test-set par k=5 -->\"+str(score*100)+'%')\n",
    "distances=['euclidean','manhattan']\n",
    "valeurs_de_k=np.arange(1,8)\n",
    "parametres_grid={\"n_neighbors\":valeurs_de_k,'metric':distances}\n",
    "model=KNeighborsClassifier()\n",
    "grid=GridSearchCV(model,parametres_grid,cv=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
